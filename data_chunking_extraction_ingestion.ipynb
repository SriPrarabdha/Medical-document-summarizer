{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/Medical_Record_File_1.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "\n",
    "import re \n",
    "\n",
    "abb = ['MD', 'DO', 'PT', 'DC', 'P.C.']\n",
    "data = {}\n",
    "# text = pages[0].page_content\n",
    "# lines = text.splitlines()\n",
    "pattern = r'(.*?)(\\d+)$'\n",
    "retry = 3\n",
    "data_found = True\n",
    "for i in range(len(pages)):\n",
    "    if not data_found:\n",
    "        retry -=1\n",
    "        print(f'No doctor found on the current page {i}. Retrying agian')\n",
    "        print(\"Total Retrys left.... \", retry)\n",
    "    \n",
    "    if retry==0:\n",
    "        break\n",
    "\n",
    "    text = pages[i].page_content\n",
    "    lines = text.splitlines()\n",
    "    data_found = False\n",
    "\n",
    "    for line in lines:\n",
    "        if any(substr in line for substr in abb):\n",
    "            match = re.search(pattern, line)\n",
    "\n",
    "            if match:\n",
    "                doctor_name = match.group(1)\n",
    "                doctor_page = match.group(2)\n",
    "                data[doctor_name] = int(doctor_page)\n",
    "                data_found = True\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import json\n",
    "import base64\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage\n",
    "import pypdfium2 as pdfium\n",
    "\n",
    "file_to_extract = \"Medical_Record_File_1\"\n",
    "# Prarabdha's API Key : AIzaSyCP1kveVOTOIMyzvEY6Xdwpq18567ETBPU\n",
    "# Krishan's API Key : AIzaSyDx7cfKeqr0YK0TE8767lnMz6G5NmeXJBI\n",
    "\n",
    "def extract_image_from_pdf(filename: str)->int:\n",
    "    \"\"\"\n",
    "    Function to extract and save, all the pages of the pdf as png images\n",
    "\n",
    "    Arg: \n",
    "        filenames : String \n",
    "\n",
    "    Returns:\n",
    "        n_pages : int\n",
    "    \"\"\"\n",
    "    pdf = pdfium.PdfDocument(\"data\\{}.pdf\".format(filename))\n",
    "    n_pages = len(pdf)\n",
    "    print(n_pages)\n",
    "    for page_number in range(n_pages):\n",
    "        page = pdf.get_page(page_number)\n",
    "        bitmap = page.render(\n",
    "            scale=3,\n",
    "        )\n",
    "        pil_image = bitmap.to_pil()\n",
    "        pil_image.save(\"all_images/{}/page{}.png\".format(filename,page_number+1))\n",
    "    \n",
    "    return n_pages\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCP1kveVOTOIMyzvEY6Xdwpq18567ETBPU\"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "model = ChatGoogleGenerativeAI(model='models/gemini-1.5-pro-latest', temperature=0.8)\n",
    "\n",
    "# Store Pdf with convert_from_path function\n",
    "n_pages = extract_image_from_pdf(file_to_extract)\n",
    "\n",
    "\n",
    "encoded_json = {}\n",
    "\n",
    "for i in range(len(n_pages)): \n",
    "    os.environ[\"GOOGLE_API_KEY_Krishan\"] = \"AIzaSyDx7cfKeqr0YK0TE8767lnMz6G5NmeXJBI\"\n",
    "\n",
    "    # Switching between API keys \n",
    "    if i%4 ==0:\n",
    "        genai.configure(api_key=os.environ[\"GOOGLE_API_KEY_Krishan\"])\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model='models/gemini-1.5-pro-latest', temperature=0.8)\n",
    "\n",
    "    with open('all_images/{}/page{}.png'.format(file_to_extract,str(i+1)), \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "        encoded_string = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "    text_message = {\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"Your task is to return me each and every thing written in this image as a plain simple text and nothing else. In some lines we find 'With/Without' and there is circle on one of the text to be selected . If 'Without' is circled then just return 'Without' in your generated answer and drop 'With' . also like if you find 'Y/N' or 'Yes/No' and one is circled then just inclued the circled one in your answer. these are just examples in general if anywhere in a line you see multiple texts separated by '/' and one of the texts is circled then just return that one and drop others. Also the content given in tables are corresponding to that particular row and add them to that only. Remove unnecessary spaces and line breaks\"\n",
    "    }\n",
    "\n",
    "    image_message = {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\" : {\"url\" : f\"data:image/jpeg;base64,{encoded_string}\"}\n",
    "    }\n",
    "\n",
    "    message = HumanMessage(content=[text_message , image_message])\n",
    "    answer = model.invoke([message])\n",
    "\n",
    "    encoded_json[i+1] = str(answer.content)\n",
    "    print(\"{}/{} || {} percentage completed\".format(i+1,n_pages, ((i+1)*100)/n_pages))\n",
    "\n",
    "save_file = open(\"Extracted_Data/{}.json\".format(file_to_extract), \"w\")\n",
    "json.dump(encoded_json, save_file, indent = 4)\n",
    "save_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "import json\n",
    "\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "embed_model = ChatGoogleGenerativeAI(model=\"models/text-embedding-004\", temperature=0.8)\n",
    "\n",
    "# embed_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "filename = \"\"\n",
    "with open(filename, 'r') as f:\n",
    "    json.load(f)\n",
    "\n",
    "result = ''\n",
    "\n",
    "# Recursive function to iterate over the JSON data\n",
    "def flatten_json(obj, path=''):\n",
    "    global result\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            new_path = f\"{path}.{key}\" if path else key\n",
    "            flatten_json(value, new_path)\n",
    "    elif isinstance(obj, list):\n",
    "        for index, item in enumerate(obj):\n",
    "            new_path = f\"{path}[{index}]\"\n",
    "            flatten_json(item, new_path)\n",
    "    else:\n",
    "        result += f\"{path}: {obj}\\n\"\n",
    "\n",
    "flatten_json(data)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = text_splitter.split_documents([result])\n",
    "\n",
    "qdrant = Qdrant.from_documents(\n",
    "    docs, \n",
    "    embed_model,\n",
    "    path = \"./db\",\n",
    "    collection_name = \"medical document\"\n",
    ")\n",
    "\n",
    "retriever = qdrant.as_retriever()\n",
    "\n",
    "#ReRanker\n",
    "\n",
    "compressor = FlashrankRerank(model=\"ms-macro-MiniLM-L-12-v2\")\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor = compressor, base_retriever=retriever)\n",
    "\n",
    "query = \"\"\n",
    "\n",
    "reranked_docs = compression_retriever.invoke(query)\n",
    "\n",
    "for doc in reranked_docs:\n",
    "    print(f\"id: {doc.metadata['_id']}\\n\")\n",
    "    print(f\"text: {doc.page_content}\\n\")\n",
    "    print(f\"score: {doc.metadata['relevance_score']}\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
